# Code Map — Core functions, classes, and connections (Merged)

This document consolidates the autogenerated core map and a detailed engines/API section for quick developer reference. Review and then replace `docs/CODE_MAP.md` when ready.

**Entry point**
- `main.py`
  - `_parse_args()` — CLI parsing and options handling.
  - `_apply_default_run_mode()` — runtime flags.
  - Creates `LiveOrchestrator` and `DashboardServer` (starts event loops / workers).

**Core runtime**
- `core/orchestrator.py`
  - `LiveOrchestrator` — primary orchestration loop.
    - Maintains symbol `ctx` objects, schedules `decision_worker_loop` and `decision_loop`.
    - Calls `EngineHub.decide()` and builds rows for the dashboard broadcast.

- `core/data_manager.py`
  - `DataManager` — async data fetchers for tickers / OHLCV / orderbook.
    - Provides `fetch_tickers`, `fetch_ohlcv`, `fetch_orderbook` used by orchestrator.

- `core/dashboard_server.py`
  - `DashboardServer` — builds payloads and serves/broadcasts UI updates.
  - Internal helpers: `_build_payload`, `_compute_eval_metrics`, `_compute_portfolio`, etc.

- `core/risk_manager.py`
  - `RiskManager`, `AccountSummary` — track risk, paper account state, and provide safety checks.

- `core/paper_broker.py`
  - `PaperBroker` — simulates order placement and fills for paper trading.

**Engine coordination**
- `engines/engine_hub.py`
  - `EngineHub` — registry and coordinator of engines. Called by `Orchestrator` to make per-symbol decisions.

**Monte Carlo (MC) engine family (key evaluation + decision code)**
- `engines/mc/monte_carlo_engine.py`
  - `MonteCarloEngine` — concrete engine implementing evaluation and decision mixins.

- `engines/mc/decision.py`
  - `MonteCarloDecisionMixin` — logic to transform entry/exit metrics into actionable decisions.

- `engines/mc/entry_evaluation.py` and `entry_evaluation_vmap.py`
  - `MonteCarloEntryEvaluationMixin`, `GlobalBatchEvaluator` — compute horizon metrics, EV, p(pos), CVaR, and other entry statistics. `entry_evaluation_vmap` provides batch/JAX-accelerated evaluation.

- `engines/mc/path_simulation.py`, `first_passage.py`, `exit_policy.py`
  - Path simulation, first-passage computations, and exit policy metrics used by evaluators.

- `engines/mc/*` (utils)
  - `params.py`, `runtime_params.py`, `leverage_optimizer_*`, `probability_jax.py`, `execution_costs.py` — helpers for MC parameterization, optimization, and math routines.

**Engines — Detailed API**

- **EngineHub**: `engines/engine_hub.py` — registry and aggregator.
  - **decide**: accepts a per-symbol `ctx`, calls each registered engine's `decide(ctx)`/`evaluate()` and returns a sanitized dict with keys: `ev`, `ev_raw`, `confidence`, `action`/`recommendation`, `meta`.
  - **decide_batch**: vectorized entry point for batch evaluation; returns a list of sanitized engine results.

- **MonteCarloEngine (core)**: `engines/mc/monte_carlo_engine.py` — composed from mixins.
  - Public surface: `decide(ctx)` / `decide_batch(ctx_list)` which rely on mixins below.

- **Entry Evaluation**: `engines/mc/entry_evaluation.py` (+ `entry_evaluation_clean.py`, `entry_evaluation_vmap.py`)
  - **evaluate_entry_metrics(...) -> dict `res`**
    - Scalars/flags: `can_enter` (bool), `ev` (float), `ev_raw` (float), `win` (float), `cvar` (float), `kelly` (float), `size_frac` (float), `direction` (int), `best_h` (int), `reason` (str)
    - `meta_detail` (dict): per-horizon arrays and diagnostic values used by the dashboard and downstream sizing logic. Keys commonly present: `policy_w_h`, `policy_ev_by_h_long`, `policy_ev_by_h_short`, `policy_p_pos_by_h`, `event_p_tp`, `event_p_sl`, `event_p_timeout`, `event_ev_r`, `event_cvar_r`, `event_t_median`, `event_t_mean`.
  - **evaluate_entry_metrics_batch(tasks) -> List[dict]**
    - Global-batch JAX path: collects symbol params, calls `simulate_paths_price_batch()`, summarizes with `summarize_gbm_horizons_jax`, integrates exit-policy metrics, produces per-symbol `res` + `perf` timings.
    - Fallback: per-symbol loop calling `evaluate_entry_metrics` when JAX/global batching not available.

- **Path simulation**: `engines/mc/path_simulation.py`
  - **simulate_paths_price(mu, sigma, s0, n_paths, n_steps, dt, ...)** -> array (n_paths, n_steps+1)
    - JAX and NumPy implementations; returns price paths for forward simulation.
  - **simulate_paths_price_batch(symbol_params_batch, ...)** -> array (num_symbols, n_paths, n_steps+1)
    - Vectorized batch generator used by global-batch evaluators (JAX optimized).
  - **simulate_paths_netpnl(paths, horizons, px_to_pnl_func, ...)** -> dict{horizon: net_pnl_array}
    - Converts simulated price paths to net P&L (fees/slippage/execution model applied) per horizon.

- **First-passage / Event metrics**: `engines/mc/first_passage.py`
  - **mc_first_passage_tp_sl(paths, tp, sl, timeout, ...)** -> dict
    - Returns `event_p_tp`, `event_p_sl`, `event_p_timeout`, `event_ev_r`, `event_cvar_r`, `event_t_median`, `event_t_mean`.
    - Used by entry evaluation to compute barrier-crossing probabilities and time-to-event stats.

- **Exit policy**: `engines/mc/exit_policy.py`
  - **compute_exit_policy_metrics(paths_or_summaries, policy_params...) -> dict/arrays**
    - Simulates roll-forward behavior under an exit policy, applies PMAKER survival/slippage mixes if enabled, returns per-horizon net-PnL summaries and diagnostic arrays used to adjust entry EVs.

- **JAX backend helpers**: `engines/mc/jax_backend.py`
  - Device init, `_JAX_OK` flag, and utilities: `summarize_gbm_horizons_jax`, `_cvar_jax`. These functions are referenced by entry/exit evaluators and the batch pipeline.

- **Policy & utility mixins** (`policy_weights.py`, `tail_sampling.py`, `execution_costs.py`, `execution_mix.py`, `cvar_methods.py`, `params.py`, `runtime_params.py`)
  - Provide small focused helpers: horizon priors, tail sampler implementations, execution cost models, CVaR ensemble implementations, and MC parameter dataclasses.

**Core trading & orchestration — Key APIs**

- **LiveOrchestrator**: `core/orchestrator.py`
  - Responsibilities: assemble per-symbol `ctx`, schedule `decision_worker_loop` (heavy compute) and `decision_loop` (UI refresh), maintain `_decision_cache`, build and broadcast rows to the dashboard.
  - Important methods: `_build_ctx_for_symbol()`, `decision_worker_loop()`, `decision_loop()`, `_rows_snapshot_cached()`, `_row()`.

- **DataManager**: `core/data_manager.py`
  - Producers: `fetch_tickers_loop`, `fetch_ohlcv_loop`, `fetch_orderbook_loop`, plus helpers `preload_all_ohlcv()`.
  - Exposes cached OHLCV / tickers / orderbook for downstream consumers.

- **DashboardServer**: `core/dashboard_server.py`
  - `_build_payload(rows, portfolio, metrics) -> dict` creates the websocket payload used by `dashboard_v2.html`.
  - `broadcast()` publishes payloads to connected clients; several HTTP endpoints for toggles and debug queries are defined here.

- **RiskManager**: `core/risk_manager.py`
  - Live guards and margin checks. Public API: `adjust_entry(ctx, suggested_size)` and `sync_leverage()` used by orchestrator before paper fills.

- **PaperBroker**: `core/paper_broker.py`
  - Simulates fills: `open_position`, `close_position`, `simulate_fill()` and keeps paper position state; used in tests and paper trading mode.

**How the MC pipeline fits into runtime**
- Orchestrator builds `ctx` containing recent market stats and signals.
- `EngineHub.decide()` calls `MonteCarloEngine.decide()` → `entry_evaluation` mixin runs (batched when possible) → `path_simulation` generates paths → `first_passage` & `exit_policy` summarize event metrics → `decision` mixin produces `kelly`/`size_frac` and `action` recommendation.
- `RiskManager` and `PaperBroker` receive the suggested action/size, enforce limits, and simulate the trade if in paper mode.

**Operational notes**
- Preserve `meta_detail` keys: the dashboard and orchestrator assume specific `meta` structure — renaming keys requires updating `LiveOrchestrator._row()` and dashboard column mappings.
- JAX availability changes behavior: tests should assert both JAX and NumPy return shapes to avoid subtle type mismatches.

---

Next recommended steps (suggested short list):
- Review `entry_evaluation.py` and add concise docstrings to exported helpers and the `evaluate_entry_metrics` return contract.
- Add explicit typed dataclasses for evaluation outputs (optional) to reduce dict-key coupling across modules.
- Merge this engines section upstream after a quick manual review.

*Autogenerated: update and refine manually.*
