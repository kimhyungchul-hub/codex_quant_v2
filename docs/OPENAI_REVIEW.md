# OpenAI Code Review — 2026-02-18 14:12

**Model:** gpt-5.2-codex
**Risk Score:** 8/10
**Summary:** 하이브리드 MC 체계 자체는 일관적이지만, 비용 이중차감과 과도한 레버리지/사이징 강제 설정이 실계좌 리스크를 급격히 키우고 있습니다. CF로 개선된 필터들이 일부 미적용 상태이며, 데이터/비용 파이프라인 정합성 보강이 필요합니다.

## Suggestions

### [P1] 하이브리드 레버리지/사이징 강제 설정 완화
**Category:** risk | **Confidence:** 84%

bybit.env에서 HYBRID_LEVERAGE=100, HYBRID_SIZE_FRAC=1.0, HYBRID_FORCE_SIZE_FRAC=1로 고정되어 있어 레짐별 cap/리스크 제어가 무력화됩니다. 실제 레짐 정책(UNI_LEV_MAX_* 등)과 불일치하며, 청산/급변동 리스크가 과도합니다. 하이브리드용 강제 설정을 비활성화하고 레짐 기반 레버리지/사이징을 사용하도록 변경하십시오.

**Env Changes:** `{'HYBRID_FORCE_LEVERAGE': '0', 'HYBRID_FORCE_SIZE_FRAC': '0', 'HYBRID_LEVERAGE': '20.0', 'HYBRID_SIZE_FRAC': '0.15'}`

**Code Changes:** engines/mc/decision.py: 하이브리드 경로에서 meta의 leverage/size_frac를 레짐 정책 max_leverage 및 UNI_MAX_POS_FRAC 기반으로 상한 적용. 하이브리드 플래너 반환값에 대해 hard cap 적용 로직 추가.

**Expected Impact:** 강제 고레버리지로 인한 급락 손실/청산 확률 감소, 포지션 집중 리스크 완화.

### [P1] net_expectancy 비용 이중차감 방지
**Category:** logic | **Confidence:** 78%

docs에서도 언급된 KNOWN ISSUE대로 MC EV에 이미 fee가 포함되어 있는데, net_expectancy에서 추가 fee_est를 차감합니다. 이중차감으로 필터가 과도하게 보수적이며 불필요한 진입 차단을 유발합니다.

**Env Changes:** `{'ENTRY_NET_EXPECTANCY_MIN': '-0.0003', 'ENTRY_NET_EXPECTANCY_MIN_CHOP': '-0.0003'}`

**Code Changes:** entry_evaluation.py 또는 필터 로직(_min_filter_states)에서 net_edge = edge_raw - fee_est를 net_edge = edge_raw 로 수정하거나, fee_est를 0으로 설정하는 옵션 플래그(예: ENTRY_NET_EXPECTANCY_FEE_ADJUST=0) 추가.

**Expected Impact:** 불필요한 진입 차단 감소, EV 판단의 정합성 회복.

### [P1] VPIN 필터 적용 (CF 최상위 개선안)
**Category:** param | **Confidence:** 70%

CF 분석에서 max_vpin=0.3이 OOS +$276 개선으로 가장 유의미합니다. 현재 env에 VPIN 상한 하드게이트가 0.95로만 존재하여 효과가 희석됩니다.

**Env Changes:** `{'UNI_MAX_VPIN_HARD': '0.30', 'CHOP_MAX_VPIN': '0.30'}`

**Code Changes:** regime_policy.py 또는 entry_evaluation.py 필터 체인에서 VPIN 하드게이트를 UNI_MAX_VPIN_HARD/CHOP_MAX_VPIN 기준으로 일관되게 적용.

**Expected Impact:** 고VPIN 구간 손실 차단으로 손실 감소 및 WR 개선.

### [P2] Volatility gate CF 파라미터 적용 (hold time 축소)
**Category:** param | **Confidence:** 63%

volatility_gate 최적안에서 chop_max_hold_sec=300이 수익 개선에 기여. 현재 POLICY_MAX_HOLD_SEC=1800으로 장기 손실 누적 가능성이 큼. 레짐별 최대 보유시간을 CF 값에 맞춰 축소 권장.

**Env Changes:** `{'TARGET_HOLD_SEC_MAX_CHOP': '300', 'POLICY_MAX_HOLD_SEC': '900'}`

**Code Changes:** regime_policy.py: chop 레짐 max_hold_sec를 env로 강제 반영하도록 기본값 조정. exit policy의 max_hold_sec를 레짐별 override 우선으로 변경.

**Expected Impact:** chop 장기 보유 손실 억제, 회전율 개선.

### [P2] MC 배치 메모리 정리 안정화
**Category:** perf | **Confidence:** 55%

entry_evaluation.py에서 대규모 배열 해제는 try/except로 되어 있으나, price_paths_batch 등 일부가 스코프 밖일 경우 예외 발생 가능. 반복 GC 및 torch 캐시 비우기가 과도하면 지연을 유발할 수 있습니다.

**Env Changes:** `{'MC_PERF_LOG': '1'}`

**Code Changes:** entry_evaluation.py: 메모리 cleanup 섹션에서 존재 여부 확인 후 del. torch cache empty는 일정 주기(예: 10회 중 1회)로 제한. perf 로그로 실제 병목 확인 후 조정.

**Expected Impact:** 불필요한 지연 감소, 안정적인 배치 처리.

## Warnings
- state/bybit.env에 API 키/Telegram 토큰이 평문 노출되어 있습니다. 즉시 로테이션 및 비공개 저장소 분리 필요.
- UNI_LEV_MIN=10과 MAX_LEVERAGE=15 조합은 저변동 구간에서 강제 고레버리지로 손실 확대 가능성이 큽니다.


---
*Auto-generated by research/openai_reviewer.py*