#!/usr/bin/env python3
"""
core/auto_diagnostics.py â€” ìë™ ì§„ë‹¨ & ìê¸° ê°œì„  ì‹œìŠ¤í…œ (Self-Improving Diagnostics Engine)

ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœê·¼ ê±°ë˜ë¥¼ ë¶„ì„í•˜ê³ , ë¬¸ì œë¥¼ ê°ì§€í•˜ì—¬ íŒŒë¼ë¯¸í„°ë¥¼ ìë™ ì¡°ì •í•©ë‹ˆë‹¤.
auto_tune_overrides.jsonì˜ ê¸°ì¡´ hot-reload íŒŒì´í”„ë¼ì¸ê³¼ í†µí•©ë©ë‹ˆë‹¤.

5ê°€ì§€ ì§„ë‹¨ ëª¨ë“ˆ:
1. Direction Accuracy â€” mu_alpha â†” direction ì •ë ¬ í’ˆì§ˆ ëª¨ë‹ˆí„°ë§
2. RegimeÃ—Side Profitability â€” ë ˆì§ë³„ ë°©í–¥ ìˆ˜ìµì„± ê°ì‹œ, ë¸”ë¡ë¦¬ìŠ¤íŠ¸ ìë™ ê°±ì‹ 
3. Time-of-Day Analysis â€” ì‹œê°„ëŒ€ë³„ ìˆ˜ìµì„± ê°ì‹œ, bad hours ìë™ ê°±ì‹ 
4. Sizing & Leverage Feedback â€” ìµœê·¼ ìŠ¹ë¥ /payoff ê¸°ë°˜ ë ˆë²„ë¦¬ì§€ ìë™ ì¡°ì •
5. Hold Duration Optimization â€” ìµœì  ë³´ìœ  ì‹œê°„ ë¶„ì„

ì‚¬ìš©ë²•:
    engine.decision_loop() ë‚´ì—ì„œ 1ì‹œê°„ë§ˆë‹¤ ìë™ í˜¸ì¶œë¨.
    ë˜ëŠ” ë…ë¦½ ì‹¤í–‰: python3 -m core.auto_diagnostics --db state/bot_data_live.db
"""
from __future__ import annotations

import json
import logging
import os
import sqlite3
import time
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

import numpy as np

logger = logging.getLogger("auto_diagnostics")

# â”€â”€â”€ ì•ˆì „ í•œê³„ (Safety Guardrails) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MAX_LEVERAGE_CHANGE = 0.15          # 1íšŒ ì¡°ì • ì‹œ ìµœëŒ€ Â±15%
MIN_COOLDOWN_SEC = 1800             # ì¡°ì • í›„ ìµœì†Œ 30ë¶„ ì¿¨ë‹¤ìš´
MIN_SAMPLE_SIZE = 20                # ìµœì†Œ ë¶„ì„ ìƒ˜í”Œ ìˆ˜
MAX_BAD_HOURS = 6                   # ìµœëŒ€ ì°¨ë‹¨ ê°€ëŠ¥ ì‹œê°„ ìˆ˜
REGIME_BLOCK_MIN_TRADES = 15        # ë ˆì§ ë¸”ë¡ íŒë‹¨ ìµœì†Œ ê±°ë˜ ìˆ˜
REGIME_BLOCK_WR_THRESHOLD = 0.38    # ì´ ì´í•˜ WRì´ë©´ ë¸”ë¡ í›„ë³´
REGIME_BLOCK_LOSS_THRESHOLD = -5.0  # ëˆ„ì  ì†ì‹¤ ê¸°ì¤€ (ë‹¬ëŸ¬)


@dataclass
class DiagnosticResult:
    """ê° ì§„ë‹¨ ëª¨ë“ˆì˜ ê²°ê³¼"""
    module: str
    severity: str  # CRITICAL / HIGH / MEDIUM / LOW / INFO
    message: str
    recommendation: dict[str, Any] = field(default_factory=dict)
    metrics: dict[str, Any] = field(default_factory=dict)


@dataclass
class AutoDiagnosticsState:
    """ì§„ë‹¨ ìƒíƒœ ì¶”ì """
    last_run_ts: float = 0.0
    last_adjust_ts: float = 0.0
    consecutive_loss_cycles: int = 0
    total_adjustments: int = 0
    adjustment_history: list[dict] = field(default_factory=list)


class AutoDiagnosticsEngine:
    """
    ìë™ ì§„ë‹¨ & ìê¸° ê°œì„  ì—”ì§„.
    
    ê¸°ì¡´ auto_tune_overrides.json íŒŒì´í”„ë¼ì¸ê³¼ í†µí•©:
    - ì§„ë‹¨ ê²°ê³¼ë¥¼ state/diagnostics_overrides.jsonì— ê¸°ë¡
    - _maybe_reload_auto_tune_overrides()ì—ì„œ mergeí•˜ì—¬ ì ìš©
    - Safety guardrailsë¡œ ê³¼ë„í•œ ë³€ê²½ ë°©ì§€
    """

    def __init__(
        self,
        db_path: str = "state/bot_data_live.db",
        output_path: str = "state/diagnostics_overrides.json",
        state_path: str = "state/diagnostics_state.json",
        lookback_hours: float = 4.0,
        interval_sec: float = 3600.0,
    ):
        self.db_path = Path(db_path)
        self.output_path = Path(output_path)
        self.state_path = Path(state_path)
        self.lookback_hours = lookback_hours
        self.interval_sec = interval_sec
        self.state = AutoDiagnosticsState()
        self._load_state()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def should_run(self) -> bool:
        """ì‹¤í–‰ ì‹œì  íŒë‹¨"""
        elapsed = time.time() - self.state.last_run_ts
        return elapsed >= self.interval_sec

    def run_diagnostics(self, extra_context: dict | None = None) -> list[DiagnosticResult]:
        """
        ì „ì²´ ì§„ë‹¨ ì‹¤í–‰ â†’ íŒŒë¼ë¯¸í„° ì¡°ì • â†’ íŒŒì¼ ê¸°ë¡

        Returns:
            DiagnosticResult ë¦¬ìŠ¤íŠ¸
        """
        self.state.last_run_ts = time.time()
        results: list[DiagnosticResult] = []

        df = self._load_recent_trades()
        if df is None or len(df) < MIN_SAMPLE_SIZE:
            logger.info(f"[AUTO_DIAG] Insufficient trades: {len(df) if df is not None else 0} < {MIN_SAMPLE_SIZE}")
            self._save_state()
            return results

        # 5ê°€ì§€ ì§„ë‹¨ ëª¨ë“ˆ ì‹¤í–‰
        results.extend(self._diag_direction_accuracy(df))
        results.extend(self._diag_regime_side(df))
        results.extend(self._diag_time_of_day(df))
        results.extend(self._diag_sizing_leverage(df))
        results.extend(self._diag_hold_duration(df))

        # ì¡°ì • ì¶”ì²œ ìˆ˜ì§‘ ë° ì ìš©
        overrides = self._collect_overrides(results)
        if overrides:
            self._apply_overrides(overrides, results)

        self._save_state()
        self._log_summary(results)
        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§„ë‹¨ ëª¨ë“ˆ 1: Direction Accuracy â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diag_direction_accuracy(self, df: list[dict]) -> list[DiagnosticResult]:
        results: list[DiagnosticResult] = []
        
        # mu_alpha alignment ë¶„ì„
        aligned = [t for t in df if t.get("pred_mu_alpha") is not None]
        if len(aligned) < MIN_SAMPLE_SIZE:
            return results

        aligned_trades = []
        misaligned_trades = []
        for t in aligned:
            mu = float(t.get("pred_mu_alpha") or 0)
            side = str(t.get("side") or "").upper()
            pnl = float(t.get("realized_pnl") or 0)
            is_aligned = (mu > 0 and side == "BUY") or (mu < 0 and side == "SELL")
            if abs(mu) < 0.001:
                continue  # mu too small to classify
            if is_aligned:
                aligned_trades.append({"pnl": pnl, "hit": 1 if pnl > 0 else 0})
            else:
                misaligned_trades.append({"pnl": pnl, "hit": 1 if pnl > 0 else 0})

        if len(aligned_trades) >= 5 and len(misaligned_trades) >= 5:
            aligned_wr = np.mean([t["hit"] for t in aligned_trades])
            misaligned_wr = np.mean([t["hit"] for t in misaligned_trades])
            aligned_pnl = sum(t["pnl"] for t in aligned_trades)
            misaligned_pnl = sum(t["pnl"] for t in misaligned_trades)
            misalign_pct = len(misaligned_trades) / (len(aligned_trades) + len(misaligned_trades)) * 100

            sev = "CRITICAL" if misaligned_wr < 0.35 and misalign_pct > 50 else \
                  "HIGH" if misaligned_wr < 0.40 else "MEDIUM"

            rec = {}
            # mu_alpha direction gate ê°•ë„ ì¡°ì ˆ
            current_min_abs = float(os.environ.get("MU_ALIGN_MIN_ABS", "0.01") or 0.01)
            if misalign_pct > 60 and misaligned_wr < 0.35:
                # ë§ì€ misalignment + ë‚˜ìœ WR â†’ min_abs ë‚®ì¶¤ (ë” ì—„ê²©í•˜ê²Œ ì°¨ë‹¨)
                new_min_abs = max(0.005, current_min_abs * 0.8)
                rec["MU_ALIGN_MIN_ABS"] = round(new_min_abs, 4)
            elif misalign_pct < 30 and aligned_wr > 0.50:
                # ì •ë ¬ ì˜ ë¨ + ì¢‹ì€ WR â†’ min_abs ë†’ì„ (ì œí•œ ì™„í™”)
                new_min_abs = min(0.05, current_min_abs * 1.2)
                rec["MU_ALIGN_MIN_ABS"] = round(new_min_abs, 4)

            results.append(DiagnosticResult(
                module="direction_accuracy",
                severity=sev,
                message=(
                    f"Aligned WR={aligned_wr:.1%} (n={len(aligned_trades)}, ${aligned_pnl:+.2f}) "
                    f"vs Misaligned WR={misaligned_wr:.1%} (n={len(misaligned_trades)}, ${misaligned_pnl:+.2f}) â€” "
                    f"{misalign_pct:.0f}% misaligned"
                ),
                recommendation=rec,
                metrics={
                    "aligned_wr": aligned_wr, "misaligned_wr": misaligned_wr,
                    "aligned_n": len(aligned_trades), "misaligned_n": len(misaligned_trades),
                    "aligned_pnl": aligned_pnl, "misaligned_pnl": misaligned_pnl,
                    "misalign_pct": misalign_pct,
                },
            ))

        # Overall WR ë¶„ì„
        all_hits = [1 if float(t.get("realized_pnl") or 0) > 0 else 0 for t in df]
        overall_wr = np.mean(all_hits) if all_hits else 0
        
        wins = [float(t["realized_pnl"]) for t in df if float(t.get("realized_pnl") or 0) > 0]
        losses = [abs(float(t["realized_pnl"])) for t in df if float(t.get("realized_pnl") or 0) < 0]
        avg_win = np.mean(wins) if wins else 0
        avg_loss = np.mean(losses) if losses else 1e-9
        payoff = avg_win / max(avg_loss, 1e-9)
        breakeven_wr = 1 / (1 + payoff) if payoff > 0 else 0.5

        if overall_wr < breakeven_wr - 0.05:
            self.state.consecutive_loss_cycles += 1
            sev = "CRITICAL" if self.state.consecutive_loss_cycles >= 3 else "HIGH"
            results.append(DiagnosticResult(
                module="direction_accuracy",
                severity=sev,
                message=f"WR={overall_wr:.1%} < BE_WR={breakeven_wr:.1%} (gap={breakeven_wr-overall_wr:.1%}, consecutive={self.state.consecutive_loss_cycles})",
                metrics={"wr": overall_wr, "breakeven_wr": breakeven_wr, "payoff": payoff},
            ))
        else:
            self.state.consecutive_loss_cycles = max(0, self.state.consecutive_loss_cycles - 1)

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§„ë‹¨ ëª¨ë“ˆ 2: Regime Ã— Side â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diag_regime_side(self, df: list[dict]) -> list[DiagnosticResult]:
        results: list[DiagnosticResult] = []
        
        combos: dict[str, list[dict]] = {}
        for t in df:
            regime = str(t.get("regime") or "unknown").lower()
            side = str(t.get("side") or "").upper()
            if side == "BUY":
                side = "LONG"
            elif side == "SELL":
                side = "SHORT"
            else:
                continue
            key = f"{regime}_{side.lower()}"
            combos.setdefault(key, []).append(t)

        current_block_str = str(os.environ.get("REGIME_SIDE_BLOCK_LIST", "") or "")
        current_blocks = {b.strip().lower() for b in current_block_str.split(",") if b.strip()}
        new_blocks = set(current_blocks)
        unblock_candidates = set()

        for combo, trades in combos.items():
            n = len(trades)
            if n < REGIME_BLOCK_MIN_TRADES:
                continue
            pnls = [float(t.get("realized_pnl") or 0) for t in trades]
            wr = np.mean([1 if p > 0 else 0 for p in pnls])
            total_pnl = sum(pnls)
            avg_pnl = np.mean(pnls)

            if combo in current_blocks:
                # ì´ë¯¸ ë¸”ë¡ëœ ì½¤ë³´ â€” í•´ì œ ì¡°ê±´ í™•ì¸ (ë³´ìˆ˜ì )
                # 30ê±°ë˜ ì´ìƒ ì‹œë®¬ê°€ í•„ìš”í•˜ì§€ë§Œ, ë¸”ë¡ë˜ì–´ ì‹¤ê±°ë˜ê°€ ì—†ìœ¼ë¯€ë¡œ ìœ ì§€
                continue

            # ìƒˆë¡œ ë¸”ë¡ ì¶”ê°€ ì¡°ê±´
            if wr < REGIME_BLOCK_WR_THRESHOLD and total_pnl < REGIME_BLOCK_LOSS_THRESHOLD and n >= REGIME_BLOCK_MIN_TRADES:
                new_blocks.add(combo)
                results.append(DiagnosticResult(
                    module="regime_side",
                    severity="HIGH",
                    message=f"{combo}: WR={wr:.1%}, PnL=${total_pnl:+.2f}, n={n} â†’ adding to BLOCK_LIST",
                    recommendation={"REGIME_SIDE_BLOCK_LIST": ",".join(sorted(new_blocks))},
                    metrics={"combo": combo, "wr": wr, "total_pnl": total_pnl, "n": n},
                ))
            elif wr < 0.40 and total_pnl < 0:
                results.append(DiagnosticResult(
                    module="regime_side",
                    severity="MEDIUM",
                    message=f"{combo}: WR={wr:.1%}, PnL=${total_pnl:+.2f}, n={n} â€” below average but not blocked yet",
                    metrics={"combo": combo, "wr": wr, "total_pnl": total_pnl, "n": n},
                ))

        # ë¸”ë¡ë¦¬ìŠ¤íŠ¸ ë³€ê²½ ì‹œ ì¶”ì²œ
        if new_blocks != current_blocks:
            results.append(DiagnosticResult(
                module="regime_side",
                severity="HIGH",
                message=f"BLOCK_LIST update: {current_blocks} â†’ {new_blocks}",
                recommendation={"REGIME_SIDE_BLOCK_LIST": ",".join(sorted(new_blocks))},
            ))

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§„ë‹¨ ëª¨ë“ˆ 3: Time-of-Day â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diag_time_of_day(self, df: list[dict]) -> list[DiagnosticResult]:
        results: list[DiagnosticResult] = []

        hourly_data: dict[int, list[float]] = {h: [] for h in range(24)}
        for t in df:
            ts = t.get("entry_time") or t.get("opened_at") or t.get("timestamp")
            if ts is None:
                continue
            try:
                if isinstance(ts, str):
                    from datetime import datetime as _dt
                    dt = _dt.fromisoformat(ts.replace("Z", "+00:00"))
                    hour = dt.hour
                elif isinstance(ts, (int, float)):
                    import time as _time
                    if ts > 1e12:
                        ts = ts / 1000  # ms â†’ sec
                    hour = _time.gmtime(ts).tm_hour
                else:
                    continue
                pnl = float(t.get("realized_pnl") or 0)
                hourly_data[hour].append(pnl)
            except Exception:
                continue

        current_bad_str = str(os.environ.get("TRADING_BAD_HOURS_UTC", "6,7") or "")
        current_bad = {int(h.strip()) for h in current_bad_str.split(",") if h.strip().isdigit()}
        new_bad = set(current_bad)

        bad_candidates = []
        for hour in range(24):
            pnls = hourly_data[hour]
            n = len(pnls)
            if n < 5:
                continue
            wr = np.mean([1 if p > 0 else 0 for p in pnls])
            total = sum(pnls)
            
            # ë‚˜ìœ ì‹œê°„ ê¸°ì¤€: WR < 35% AND ì´ ì†ì‹¤ AND ìµœì†Œ 5ê±°ë˜
            if wr < 0.35 and total < -2.0 and hour not in current_bad:
                bad_candidates.append((hour, wr, total, n))

        # ê°€ì¥ ë‚˜ìœ ì‹œê°„ëŒ€ë§Œ ì¶”ê°€ (MAX_BAD_HOURS ì œí•œ)
        bad_candidates.sort(key=lambda x: x[2])  # ì†ì‹¤ í° ìˆœ
        for hour, wr, total, n in bad_candidates:
            if len(new_bad) >= MAX_BAD_HOURS:
                break
            new_bad.add(hour)
            results.append(DiagnosticResult(
                module="time_of_day",
                severity="HIGH",
                message=f"UTC {hour}h: WR={wr:.1%}, PnL=${total:+.2f}, n={n} â†’ adding to BAD_HOURS",
                recommendation={"TRADING_BAD_HOURS_UTC": ",".join(str(h) for h in sorted(new_bad))},
                metrics={"hour": hour, "wr": wr, "total_pnl": total, "n": n},
            ))

        # í•´ì œ í›„ë³´: í˜„ì¬ ë¸”ë¡ëœ ì‹œê°„ì´ ìµœê·¼ì— ì¢‹ì•„ì¡Œë‹¤ë©´
        for hour in list(current_bad):
            pnls = hourly_data.get(hour, [])
            # ë¸”ë¡ëœ ì‹œê°„ì€ ê±°ë˜ê°€ ì—†ìœ¼ë¯€ë¡œ íŒë‹¨ ë¶ˆê°€ â†’ ìœ ì§€
            # (ë‹¨, ë§¤ë‰´ì–¼ í•´ì œë¥¼ ìœ„í•œ ë¡œê·¸ëŠ” ë‚¨ê¹€)

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§„ë‹¨ ëª¨ë“ˆ 4: Sizing & Leverage â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diag_sizing_leverage(self, df: list[dict]) -> list[DiagnosticResult]:
        results: list[DiagnosticResult] = []

        # ìµœê·¼ ê±°ë˜ì˜ notional-binned ì„±ê³¼ ë¶„ì„
        notional_bins = [
            ("tiny", 0, 50),
            ("small", 50, 200),
            ("medium", 200, 500),
            ("large", 500, float("inf")),
        ]

        for label, lo, hi in notional_bins:
            trades = [t for t in df if lo <= abs(float(t.get("notional") or 0)) < hi]
            if len(trades) < 5:
                continue
            pnls = [float(t.get("realized_pnl") or 0) for t in trades]
            wr = np.mean([1 if p > 0 else 0 for p in pnls])
            total = sum(pnls)

            wins = [p for p in pnls if p > 0]
            losses = [abs(p) for p in pnls if p < 0]
            payoff = np.mean(wins) / max(np.mean(losses), 1e-9) if wins and losses else 1.0

            if payoff < 1.0 and total < -5.0 and label in ("medium", "large"):
                rec = {}
                # í° ì‚¬ì´ì¦ˆì—ì„œ payoff < 1 â†’ ë ˆë²„ë¦¬ì§€ ì¶•ì†Œ ì¶”ì²œ
                current_max = float(os.environ.get("LEVERAGE_TARGET_MAX", "25") or 25)
                new_max = max(3.0, current_max * (1 - MAX_LEVERAGE_CHANGE))
                # Note: LEVERAGE_TARGET_MAX is in blocklist, so use LEVERAGE_DYNAMIC_MIN_SCALE
                current_scale = float(os.environ.get("LEVERAGE_DYNAMIC_MIN_SCALE", "0.4") or 0.4)
                new_scale = max(0.2, current_scale * 0.9)
                rec["LEVERAGE_DYNAMIC_MIN_SCALE"] = round(new_scale, 3)

                results.append(DiagnosticResult(
                    module="sizing_leverage",
                    severity="HIGH",
                    message=f"{label} notional (${lo}-${hi}): payoff={payoff:.2f}, WR={wr:.1%}, PnL=${total:+.2f} â†’ reduce leverage",
                    recommendation=rec,
                    metrics={"bin": label, "wr": wr, "payoff": payoff, "total_pnl": total, "n": len(trades)},
                ))
            elif payoff > 1.5 and wr > 0.45 and total > 5.0:
                results.append(DiagnosticResult(
                    module="sizing_leverage",
                    severity="INFO",
                    message=f"{label} notional: payoff={payoff:.2f}, WR={wr:.1%}, PnL=${total:+.2f} â€” profitable bin",
                    metrics={"bin": label, "wr": wr, "payoff": payoff, "total_pnl": total, "n": len(trades)},
                ))

        # ì „ì²´ ë ˆë²„ë¦¬ì§€ vs PnL ìƒê´€ ë¶„ì„
        leverages = []
        pnls_all = []
        for t in df:
            lev = float(t.get("leverage") or 0)
            pnl = float(t.get("realized_pnl") or 0)
            if lev > 0:
                leverages.append(lev)
                pnls_all.append(pnl)
        
        if len(leverages) >= 10:
            corr = float(np.corrcoef(leverages, pnls_all)[0, 1]) if np.std(leverages) > 0 else 0
            if corr < -0.15:
                results.append(DiagnosticResult(
                    module="sizing_leverage",
                    severity="HIGH",
                    message=f"Leverage-PnL correlation = {corr:.3f} (higher leverage â†’ worse PnL) â€” consider reducing",
                    metrics={"lev_pnl_corr": corr, "n": len(leverages)},
                ))

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì§„ë‹¨ ëª¨ë“ˆ 5: Hold Duration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diag_hold_duration(self, df: list[dict]) -> list[DiagnosticResult]:
        results: list[DiagnosticResult] = []

        duration_bins = [
            ("flash", 0, 60),
            ("short", 60, 300),
            ("medium", 300, 3600),
            ("long", 3600, float("inf")),
        ]

        for label, lo_sec, hi_sec in duration_bins:
            trades = [
                t for t in df
                if lo_sec <= float(t.get("hold_duration_sec") or 0) < hi_sec
                and float(t.get("hold_duration_sec") or 0) > 0
            ]
            if len(trades) < 5:
                continue

            pnls = [float(t.get("realized_pnl") or 0) for t in trades]
            wr = np.mean([1 if p > 0 else 0 for p in pnls])
            total = sum(pnls)

            if label == "flash" and wr < 0.30 and total < -2.0:
                # Flash trades lose â†’ increase min hold or reduce entries
                current_min_hold = float(os.environ.get("EXIT_MIN_HOLD_SEC", "30") or 30)
                new_min_hold = min(180, int(current_min_hold * 1.5))
                results.append(DiagnosticResult(
                    module="hold_duration",
                    severity="HIGH",
                    message=f"Flash (<1min) trades: WR={wr:.1%}, PnL=${total:+.2f}, n={len(trades)} â†’ increase min hold",
                    recommendation={"EXIT_MIN_HOLD_SEC": str(new_min_hold)},
                    metrics={"bin": label, "wr": wr, "total_pnl": total, "n": len(trades)},
                ))
            elif label == "long" and wr > 0.50 and total > 0:
                results.append(DiagnosticResult(
                    module="hold_duration",
                    severity="INFO",
                    message=f"Long holds (>1h): WR={wr:.1%}, PnL=${total:+.2f}, n={len(trades)} â€” profitable duration",
                    metrics={"bin": label, "wr": wr, "total_pnl": total, "n": len(trades)},
                ))

        return results

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Override ìˆ˜ì§‘ ë° ì ìš© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _collect_overrides(self, results: list[DiagnosticResult]) -> dict[str, str]:
        """ëª¨ë“  ì§„ë‹¨ ê²°ê³¼ì—ì„œ ì¶”ì²œëœ overridesë¥¼ ìˆ˜ì§‘"""
        overrides: dict[str, str] = {}
        for r in results:
            if r.recommendation:
                for k, v in r.recommendation.items():
                    overrides[k] = str(v)
        return overrides

    def _apply_overrides(self, overrides: dict[str, str], results: list[DiagnosticResult]) -> None:
        """overridesë¥¼ íŒŒì¼ì— ê¸°ë¡ (hot-reloadìš©)"""
        # ì¿¨ë‹¤ìš´ ì²´í¬
        elapsed = time.time() - self.state.last_adjust_ts
        if elapsed < MIN_COOLDOWN_SEC:
            logger.info(f"[AUTO_DIAG] Cooldown active: {elapsed:.0f}s < {MIN_COOLDOWN_SEC}s")
            return

        # ê¸°ì¡´ auto_tune_overrides.jsonê³¼ merge
        merged = {}
        auto_tune_path = self.output_path.parent / "auto_tune_overrides.json"
        if auto_tune_path.exists():
            try:
                with open(auto_tune_path) as f:
                    existing = json.load(f)
                if isinstance(existing, dict):
                    merged = existing.get("overrides", existing)
            except Exception:
                pass

        # ìƒˆ overridesë¥¼ merge
        for k, v in overrides.items():
            merged[k] = v

        # diagnostics_overrides.jsonì— ê¸°ë¡
        payload = {
            "timestamp_ms": int(time.time() * 1000),
            "source": "auto_diagnostics",
            "interval_hours": self.lookback_hours,
            "n_adjustments": len(overrides),
            "overrides": overrides,
            "diagnostics_summary": [
                {
                    "module": r.module,
                    "severity": r.severity,
                    "message": r.message[:200],
                }
                for r in results
                if r.severity in ("CRITICAL", "HIGH")
            ],
        }

        try:
            self.output_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.output_path, "w") as f:
                json.dump(payload, f, indent=2, ensure_ascii=False)
            logger.info(f"[AUTO_DIAG] Wrote {len(overrides)} overrides to {self.output_path}")
        except Exception as e:
            logger.error(f"[AUTO_DIAG] Failed to write overrides: {e}")
            return

        # auto_tune_overrides.jsonì—ë„ mergeí•˜ì—¬ ê¸°ë¡ (ê¸°ì¡´ ê²ƒì— ì¶”ê°€)
        try:
            if auto_tune_path.exists():
                with open(auto_tune_path) as f:
                    orig = json.load(f)
            else:
                orig = {"overrides": {}}

            if isinstance(orig, dict):
                if "overrides" not in orig:
                    orig["overrides"] = {}
                for k, v in overrides.items():
                    orig["overrides"][k] = v
                orig["diagnostics_timestamp_ms"] = int(time.time() * 1000)
                orig["diagnostics_n_adjustments"] = len(overrides)

                with open(auto_tune_path, "w") as f:
                    json.dump(orig, f, indent=2, ensure_ascii=False)
                logger.info(f"[AUTO_DIAG] Merged {len(overrides)} overrides into auto_tune_overrides.json")
        except Exception as e:
            logger.error(f"[AUTO_DIAG] Failed to merge into auto_tune: {e}")

        self.state.last_adjust_ts = time.time()
        self.state.total_adjustments += 1
        self.state.adjustment_history.append({
            "ts": time.time(),
            "overrides": overrides,
            "reason": [r.message[:100] for r in results if r.severity in ("CRITICAL", "HIGH")],
        })
        # íˆìŠ¤í† ë¦¬ í¬ê¸° ì œí•œ
        if len(self.state.adjustment_history) > 100:
            self.state.adjustment_history = self.state.adjustment_history[-50:]

        self._save_state()

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ DB ì ‘ê·¼ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_recent_trades(self) -> list[dict] | None:
        """ìµœê·¼ Nì‹œê°„ ë‚´ closed ê±°ë˜ë¥¼ DBì—ì„œ ë¡œë“œ"""
        if not self.db_path.exists():
            logger.warning(f"[AUTO_DIAG] DB not found: {self.db_path}")
            return None

        cutoff_ms = int((time.time() - self.lookback_hours * 3600) * 1000)
        
        try:
            conn = sqlite3.connect(str(self.db_path), timeout=5)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # í…Œì´ë¸” ì¡´ì¬ í™•ì¸
            cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='trades'")
            if not cursor.fetchone():
                conn.close()
                return None

            # ì»¬ëŸ¼ ëª©ë¡ í™•ì¸
            cursor.execute("PRAGMA table_info(trades)")
            columns = {row[1] for row in cursor.fetchall()}
            
            # ì‹œê°„ í•„í„° ì»¬ëŸ¼ ê²°ì •
            time_col = "closed_at_ms" if "closed_at_ms" in columns else \
                       "exit_time" if "exit_time" in columns else \
                       "timestamp" if "timestamp" in columns else None

            if time_col is None:
                # timestamp ì—†ìœ¼ë©´ ìµœê·¼ Nê±´
                cursor.execute(f"SELECT * FROM trades ORDER BY rowid DESC LIMIT 500")
            else:
                cursor.execute(
                    f"SELECT * FROM trades WHERE {time_col} > ? ORDER BY {time_col} DESC LIMIT 1000",
                    (cutoff_ms,)
                )

            rows = cursor.fetchall()
            conn.close()

            if not rows:
                return None

            # dictë¡œ ë³€í™˜
            result = []
            for row in rows:
                d = {k: row[k] for k in row.keys()}
                result.append(d)
            return result

        except Exception as e:
            logger.error(f"[AUTO_DIAG] DB query failed: {e}")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ State ê´€ë¦¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _load_state(self):
        if self.state_path.exists():
            try:
                with open(self.state_path) as f:
                    data = json.load(f)
                self.state.last_run_ts = data.get("last_run_ts", 0)
                self.state.last_adjust_ts = data.get("last_adjust_ts", 0)
                self.state.consecutive_loss_cycles = data.get("consecutive_loss_cycles", 0)
                self.state.total_adjustments = data.get("total_adjustments", 0)
                self.state.adjustment_history = data.get("adjustment_history", [])
            except Exception:
                pass

    def _save_state(self):
        try:
            self.state_path.parent.mkdir(parents=True, exist_ok=True)
            with open(self.state_path, "w") as f:
                json.dump({
                    "last_run_ts": self.state.last_run_ts,
                    "last_adjust_ts": self.state.last_adjust_ts,
                    "consecutive_loss_cycles": self.state.consecutive_loss_cycles,
                    "total_adjustments": self.state.total_adjustments,
                    "adjustment_history": self.state.adjustment_history[-20:],
                }, f, indent=2)
        except Exception:
            pass

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¡œê¹… â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _log_summary(self, results: list[DiagnosticResult]):
        """ì§„ë‹¨ ê²°ê³¼ ìš”ì•½ ë¡œê·¸"""
        if not results:
            logger.info("[AUTO_DIAG] No findings in this cycle")
            return

        by_sev = {}
        for r in results:
            by_sev.setdefault(r.severity, []).append(r)

        summary_parts = []
        for sev in ("CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO"):
            items = by_sev.get(sev, [])
            if items:
                summary_parts.append(f"{sev}={len(items)}")

        logger.info(f"[AUTO_DIAG] {len(results)} findings: {', '.join(summary_parts)}")
        for r in results:
            if r.severity in ("CRITICAL", "HIGH"):
                logger.warning(f"[AUTO_DIAG][{r.severity}] [{r.module}] {r.message}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Dashboard í†µí•© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_dashboard_payload(self) -> dict:
        """ëŒ€ì‹œë³´ë“œì— í‘œì‹œí•  ì§„ë‹¨ ìƒíƒœ ìš”ì•½"""
        diag_payload = {
            "last_run_ts": self.state.last_run_ts,
            "last_adjust_ts": self.state.last_adjust_ts,
            "total_adjustments": self.state.total_adjustments,
            "consecutive_loss_cycles": self.state.consecutive_loss_cycles,
            "interval_sec": self.interval_sec,
        }
        # ë§ˆì§€ë§‰ ì¡°ì • ë‚´ì—­
        if self.state.adjustment_history:
            last = self.state.adjustment_history[-1]
            diag_payload["last_adjustment"] = {
                "ts": last.get("ts"),
                "n_overrides": len(last.get("overrides", {})),
                "reasons": last.get("reason", [])[:3],
            }
        return diag_payload


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI ì‹¤í–‰ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    import argparse
    parser = argparse.ArgumentParser(description="Auto Diagnostics Engine")
    parser.add_argument("--db", default="state/bot_data_live.db", help="DB path")
    parser.add_argument("--hours", type=float, default=4.0, help="Lookback hours")
    parser.add_argument("--output", default="state/diagnostics_overrides.json", help="Output path")
    parser.add_argument("--dry-run", action="store_true", help="Don't write overrides")
    args = parser.parse_args()

    logging.basicConfig(level=logging.INFO, format="%(asctime)s %(levelname)s %(message)s")

    engine = AutoDiagnosticsEngine(
        db_path=args.db,
        output_path=args.output,
        lookback_hours=args.hours,
    )

    # Force run (ignore interval)
    engine.state.last_run_ts = 0

    results = engine.run_diagnostics()

    print(f"\n{'=' * 70}")
    print(f"AUTO DIAGNOSTICS REPORT ({len(results)} findings)")
    print(f"{'=' * 70}")
    for r in results:
        marker = {"CRITICAL": "ğŸ”´", "HIGH": "ğŸŸ ", "MEDIUM": "ğŸŸ¡", "LOW": "ğŸ”µ", "INFO": "âšª"}.get(r.severity, "âšª")
        print(f"\n{marker} [{r.severity}] [{r.module}]")
        print(f"   {r.message}")
        if r.recommendation:
            print(f"   â†’ Override: {r.recommendation}")

    if args.dry_run:
        print("\n[DRY-RUN] No overrides written.")
    else:
        overrides = engine._collect_overrides(results)
        if overrides:
            print(f"\nğŸ“ {len(overrides)} overrides written to {args.output}")
        else:
            print("\nâœ… No parameter changes recommended.")

    print(f"\nState: {engine.state_path}")


if __name__ == "__main__":
    main()
