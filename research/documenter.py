"""
research/documenter.py â€” Auto-Documentation Module
====================================================
CF ì—°êµ¬ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ ë¬¸ì„œí™”í•˜ê³  ê¸°ì¡´ docsì— ë°˜ì˜.
- Findings â†’ docs/RESEARCH_FINDINGS.md (ì£¼ê¸°ì  ê°±ì‹ )
- ì¤‘ìš” ë°œê²¬ â†’ copilot-instructions.md Change Log í˜•ì‹ ì¶œë ¥
- CODE_MAP_v2.md ì—…ë°ì´íŠ¸ ì œì•ˆ ìƒì„±
"""
from __future__ import annotations

import json
import logging
import os
import time
from datetime import datetime
from pathlib import Path
from typing import Any

logger = logging.getLogger("research.documenter")

FINDINGS_DOC_PATH = "docs/RESEARCH_FINDINGS.md"
RESEARCH_LOG_PATH = "state/research_findings.json"


def save_findings_json(findings: list[dict], path: str = RESEARCH_LOG_PATH):
    """Save findings to JSON for persistence."""
    try:
        existing = []
        if os.path.exists(path):
            with open(path, "r", encoding="utf-8") as f:
                existing = json.load(f)
        # Merge by finding_id
        existing_ids = {f["finding_id"] for f in existing}
        for f in findings:
            if f.get("finding_id") not in existing_ids:
                existing.append(f)
        with open(path, "w", encoding="utf-8") as f:
            json.dump(existing, f, indent=2, default=str, ensure_ascii=False)
        logger.info(f"Saved {len(findings)} findings to {path}")
    except Exception as e:
        logger.error(f"Failed to save findings: {e}")


def generate_findings_markdown(
    findings: list[dict],
    baseline: dict,
    baseline_by_regime: dict,
    output_path: str = FINDINGS_DOC_PATH,
):
    """Generate/update the research findings markdown document."""
    now = datetime.now().strftime("%Y-%m-%d %H:%M")
    lines = [
        f"# Research Findings â€” Counterfactual Analysis",
        f"",
        f"> Auto-generated: {now}",
        f"> Baseline: {baseline.get('n', 0)} trades, PnL=${baseline.get('pnl', 0):.2f}, "
        f"WR={baseline.get('wr', 0):.1%}, R:R={baseline.get('rr', 0):.2f}",
        f"",
        f"## Pipeline Stage Impact Summary",
        f"",
    ]

    # Group findings by stage
    by_stage: dict[str, list[dict]] = {}
    for f in findings:
        stage = f.get("stage", "unknown")
        by_stage.setdefault(stage, []).append(f)

    stage_descriptions = {
        "leverage": "ë ˆë²„ë¦¬ì§€ ê²°ì •",
        "tp_sl": "TP/SL íƒ€ê²Ÿ",
        "hold_duration": "ë³´ìœ  ì‹œê°„",
        "entry_filter": "ì§„ì… í•„í„°",
        "direction": "ë°©í–¥ ê²°ì •",
        "vpin_filter": "VPIN í•„í„°",
        "exit_reason": "ì²­ì‚° ë¡œì§",
        "capital_allocation": "ìë³¸ ë¶„ë°°",
        "regime_multiplier": "ë ˆì§ ë³´ì •",
    }

    for stage, stage_findings in by_stage.items():
        desc = stage_descriptions.get(stage, stage)
        best = max(stage_findings, key=lambda f: f.get("improvement_pct", 0))
        lines.append(f"### {stage.upper()} â€” {desc}")
        lines.append(f"")
        lines.append(f"**Best Finding:** {best.get('title', '')}")
        lines.append(f"- Improvement: ${best.get('improvement_pct', 0):+.2f}")
        lines.append(f"- Confidence: {best.get('confidence', 0):.0%}")
        lines.append(f"- Parameters: `{json.dumps(best.get('param_changes', {}))}`")
        lines.append(f"")
        if best.get("recommendation"):
            lines.append(f"```")
            lines.append(best["recommendation"])
            lines.append(f"```")
            lines.append(f"")
        # Comparison table
        bl = best.get("baseline_metrics", {})
        im = best.get("improved_metrics", {})
        lines.append(f"| Metric | Baseline | CF | Delta |")
        lines.append(f"|--------|----------|----|----|")
        for k in ["n", "pnl", "wr", "rr", "edge", "sharpe", "pf"]:
            bv = bl.get(k, 0)
            iv = im.get(k, 0)
            dv = iv - bv if isinstance(bv, (int, float)) else 0
            fmt = ".4f" if k in ("wr", "edge") else ".2f" if k in ("pnl", "rr", "sharpe", "pf") else "d"
            lines.append(f"| {k} | {bv:{fmt}} | {iv:{fmt}} | {dv:+{fmt}} |")
        lines.append(f"")

    # Regime performance
    lines.append(f"## Regime Performance Breakdown")
    lines.append(f"")
    lines.append(f"| Regime | N | PnL | WR | R:R | Edge |")
    lines.append(f"|--------|---|-----|----|----|------|")
    for regime, m in baseline_by_regime.items():
        lines.append(
            f"| {regime} | {m.get('n', 0)} | ${m.get('pnl', 0):.2f} | "
            f"{m.get('wr', 0):.1%} | {m.get('rr', 0):.2f} | {m.get('edge', 0):+.1%} |"
        )
    lines.append(f"")

    # Action items
    lines.append(f"## ğŸ¯ Recommended Actions")
    lines.append(f"")
    for i, f in enumerate(sorted(findings, key=lambda x: x.get("improvement_pct", 0), reverse=True)[:5], 1):
        lines.append(f"{i}. **{f.get('title', '')}** (Î”PnL: ${f.get('improvement_pct', 0):+.2f}, confidence: {f.get('confidence', 0):.0%})")
        if f.get("param_changes"):
            for pk, pv in f["param_changes"].items():
                lines.append(f"   - `{pk}` = `{pv}`")
        lines.append(f"")

    content = "\n".join(lines)
    try:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(content)
        logger.info(f"Generated {output_path} ({len(findings)} findings)")
    except Exception as e:
        logger.error(f"Failed to write {output_path}: {e}")

    return content


def generate_changelog_entry(findings: list[dict]) -> str:
    """Generate a Change Log entry for copilot-instructions.md."""
    if not findings:
        return ""
    now = datetime.now().strftime("%Y-%m-%d")
    lines = [f"### [{now}] Research Engine â€” CF ë¶„ì„ ê²°ê³¼"]
    lines.append(f"**ë°œê²¬:** {len(findings)}ê°œì˜ ìœ ì˜ë¯¸í•œ íŒŒë¼ë¯¸í„° ìµœì í™” ë°œê²¬")
    lines.append(f"")
    for f in findings[:5]:
        lines.append(f"- **{f.get('stage', '').upper()}**: {f.get('title', '')} "
                     f"(Î”PnL: ${f.get('improvement_pct', 0):+.2f}, ì‹ ë¢°ë„: {f.get('confidence', 0):.0%})")
    lines.append(f"")
    lines.append(f"**ì˜í–¥ íŒŒì¼:** `research/cf_engine.py`, `docs/RESEARCH_FINDINGS.md`")
    return "\n".join(lines)
